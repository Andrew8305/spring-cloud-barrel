<?xml version="1.0" encoding="UTF-8" ?>
<!--日志级别以及优先级排序: OFF > FATAL > ERROR > WARN > INFO > DEBUG > TRACE > ALL -->
<!--Configuration后面的status，这个用于设置log4j2自身内部的信息输出，可以不设置，当设置成trace时，你会看到log4j2内部各种详细输出-->
<!--monitorInterval：Log4j能够自动检测修改配置 文件和重新配置本身，设置间隔秒数-->
<!--shutdownHook:指定当JVM停止的时候，Log4j是否应该停止。停止钩子默认是启用的，也可以通过设置这个属性点值为disable来禁用它，这样我们就可以完全记录应用的整个生命周期。-->
<!--monitorInterval="3600" 指log4j2每隔 3600 秒（1小时），自动监控该配置文件是否有变化，如果变化，则自动根据文件内容重新配置。-->
<Configuration monitoringInterval="3600" shutdownHook="disable">
    <Properties>
        <Property name="basedir">logs/cehn-monitor</Property>
        <Property name="all-logger">all-logger</Property>
    </Properties>
    <Appenders>
        <!--控制台日志输出设置 start-->
        <Console name="to-console" target="SYSTEM_OUT">
            <PatternLayout pattern="%highlight{[%d{yyyy-MM-dd HH:mm:ss.SSS}] - [%p] - [%c:%L] - [Method = %M] - [%m]}%n"/>
        </Console>
        <!--控制台日志输出设置 end-->
        <!--文件日志输出设置 start-->
        <!--filePattern：表示当日志到达指定的大小或者时间，产生新日志时，旧日志的命名路径。-->
        <!--Policies：策略，表示日志什么时候应该产生新日志，可以有时间策略和大小策略等-->
        <RollingFile name="${all-logger}" fileName="${basedir}/${all-logger}.log" append="true" filePattern="${basedir}/$${date:yyyy-MM}/${all-logger}-%d{yyyy-MM-dd}-%i.log.gz">
            <PatternLayout pattern="%highlight{[%d{yyyy-MM-dd HH:mm:ss.SSS}] - [%p] - [%c:%L] - [Method = %M] - [%m]}%n"/>
            <Policies>
                <OnStartupTriggeringPolicy/>
                <SizeBasedTriggeringPolicy size="50 MB"/><!-- 每到50M生成一个日志文件 -->
                <TimeBasedTriggeringPolicy/>
            </Policies>
            <!-- 最大保存文件数，超过的删除 -->
            <DefaultRolloverStrategy max="30" compressionLevel="9">
                <Delete basePath="${basedir}" maxDepth="2">
                    <IfFileName glob="*/*.log.gz"/>
                    <IfLastModified age="7d"/>
                </Delete>
            </DefaultRolloverStrategy>
        </RollingFile>

        <!--文件日志输出设置 end-->

        <!--Kafka日志输出设置 start-->
        <!--设置topic-->
        <Kafka name="KafkaLog" topic="log" ignoreExceptions="false">
            <PatternLayout pattern="{[%d{yyyy-MM-dd HH:mm:ss.SSS}] - [%p] - [%c:%L] - [Method = %M] - [%m]}"/>
            <!--设置Kafka连接-->
            <Property name="bootstrap.servers">http://centOS:9094</Property>
            <!--设置最大阻塞时间-->
            <Property name="max.block.ms">2000</Property>
        </Kafka>

        <!--当Kafka宕机时采取写本地文件-->
        <RollingFile name="failoverKafkaLog" fileName="${basedir}/kafka/failoverKafkaLog.log" append="true"
                     filePattern="${basedir}/kafka/$${date:yyyy-MM}/failoverKafkaLog-%d{yyyy-MM-dd}-%i.log.gz">
            <ThresholdFilter level="INFO" onMatch="ACCEPT" onMismatch="DENY"/>
            <PatternLayout
                    pattern="%highlight{[%d{yyyy-MM-dd HH:mm:ss.SSS}] - [%p] - [%c:%L] - [Method = %M] - [%m]}%n"/>
            <Policies>
                <OnStartupTriggeringPolicy/>
                <SizeBasedTriggeringPolicy size="50 MB"/><!-- 每到50M生成一个日志文件 -->
                <TimeBasedTriggeringPolicy/>
            </Policies>
            <!-- 最大保存文件数，超过的删除 -->
            <DefaultRolloverStrategy max="30" compressionLevel="9">
                <Delete basePath="${basedir}" maxDepth="2">
                    <IfFileName glob="*/*.log.gz"/>
                    <IfLastModified age="7d"/>
                </Delete>
            </DefaultRolloverStrategy>

        </RollingFile>

        <!--设置策略-->
        <Failover name="KafkaFailover" primary="KafkaLog" retryIntervalSeconds="600">
            <Failovers>
                <AppenderRef ref="failoverKafkaLog"/>
            </Failovers>
        </Failover>
        <!--Kafka日志输出设置 end-->
    </Appenders>

    <!--监控日志的位置设置 start-->
    <Loggers>
        <!--采用异步记录-->
        <AsyncRoot level="info">
            <AppenderRef ref="to-console"/>
            <!--<AppenderRef ref="${all-logger}"/>-->
            <AppenderRef ref="KafkaFailover"/>
        </AsyncRoot>
    </Loggers>
    <!--监控日志的位置设置 end-->

</Configuration>